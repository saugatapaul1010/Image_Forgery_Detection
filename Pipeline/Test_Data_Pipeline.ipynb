{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://machinelearninguru.com/deep_learning/data_preparation/hdf5/hdf5.html\n",
    "#https://www.kaggle.com/crawford/resize-and-save-images-as-hdf5-256x256\n",
    "\n",
    "import os\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import h5py\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"test_images/\"\n",
    "files = os.listdir(folder)\n",
    "hdf5_path = 'test_imgs_v2.hdf5'\n",
    "\n",
    "n=len(files)\n",
    "\n",
    "#Check the order of data and chose proper data shape to save images\n",
    "train_shape = (n, 256, 256, 3)\n",
    "test_shape = (n,256,256)\n",
    "\n",
    "hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "hdf5_file.create_dataset(name=\"test_img\", \n",
    "                         shape=train_shape, \n",
    "                         compression=None)\n",
    "\n",
    "hdf5_file.create_dataset(name=\"test_labels\", \n",
    "                         shape=test_shape,\n",
    "                         compression=None)\n",
    "\n",
    "for i,file_name in enumerate(files):\n",
    "    \n",
    "    #Read the images\n",
    "    rgb_img = Image.open(folder+file_name)\n",
    "    rgb_img = rgb_img.resize((256,256))\n",
    "    \n",
    "    #Convert to grayscale\n",
    "    gray_img = rgb_img.convert('L')\n",
    "    \n",
    "    hdf5_file[\"test_img\"][i, ...] = rgb_img\n",
    "    hdf5_file[\"test_labels\"][i, ...] = gray_img\n",
    "\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extrating for image # 1, with shape-->(64, 240)\n",
      "Feature extrating for image # 2, with shape-->(64, 240)\n",
      "Feature extrating for image # 3, with shape-->(64, 240)\n",
      "Feature extrating for image # 4, with shape-->(64, 240)\n",
      "Feature extrating for image # 5, with shape-->(64, 240)\n",
      "Feature extrating for image # 6, with shape-->(64, 240)\n",
      "Feature extrating for image # 7, with shape-->(64, 240)\n",
      "Feature extrating for image # 8, with shape-->(64, 240)\n",
      "Feature extrating for image # 9, with shape-->(64, 240)\n",
      "Feature extrating for image # 10, with shape-->(64, 240)\n",
      "Feature extrating for image # 11, with shape-->(64, 240)\n",
      "Feature extrating for image # 12, with shape-->(64, 240)\n",
      "Feature extrating for image # 13, with shape-->(64, 240)\n",
      "Feature extrating for image # 14, with shape-->(64, 240)\n",
      "Feature extrating for image # 15, with shape-->(64, 240)\n",
      "Feature extrating for image # 16, with shape-->(64, 240)\n",
      "Feature extrating for image # 17, with shape-->(64, 240)\n",
      "Feature extrating for image # 18, with shape-->(64, 240)\n",
      "Feature extrating for image # 19, with shape-->(64, 240)\n",
      "Feature extrating for image # 20, with shape-->(64, 240)\n",
      "Feature extrating for image # 21, with shape-->(64, 240)\n",
      "Feature extrating for image # 22, with shape-->(64, 240)\n",
      "Feature extrating for image # 23, with shape-->(64, 240)\n",
      "Feature extrating for image # 24, with shape-->(64, 240)\n",
      "Feature extrating for image # 25, with shape-->(64, 240)\n",
      "Feature extrating for image # 26, with shape-->(64, 240)\n",
      "Feature extrating for image # 27, with shape-->(64, 240)\n",
      "Feature extrating for image # 28, with shape-->(64, 240)\n",
      "Feature extrating for image # 29, with shape-->(64, 240)\n",
      "Feature extrating for image # 30, with shape-->(64, 240)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "import os,sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import time\n",
    "import skimage\n",
    "import skimage.io, skimage.transform\n",
    "from skimage.transform import resize\n",
    "from skimage.util import view_as_windows\n",
    "import scipy.misc\n",
    "import scipy.io as sio\n",
    "from utils import *\n",
    "from skimage import img_as_uint\n",
    "#imagefname = 'purple_bus_rbcfbeb24t_crop.png'\n",
    "#imagefpath = os.path.join(thispath,imagefname)\n",
    "\n",
    "# load image file\n",
    "hdf5_file = h5py.File('test_imgs_feat_v2.hdf5', mode='w')\n",
    "\n",
    "hdf5=h5py.File('test_imgs_v2.hdf5','r')\n",
    "imgs=np.array(hdf5['test_img'])\n",
    "hdf5.close()\n",
    "\n",
    "\n",
    "feat_shape=(np.shape(imgs)[0],64,240)\n",
    "\n",
    "\n",
    "hdf5_file.create_dataset(\"feat\",feat_shape, np.float32)\n",
    "for q in range(0,np.shape(imgs)[0]):\n",
    "    im=imgs[q]\n",
    "    # extract square patches with stride (step) 8\n",
    "    patchsize=32\n",
    "\n",
    "    # reshape to a list of patches\n",
    "    rgb_patches = view_as_windows(im,(32,32,3),32)\n",
    "    rgb_patches = np.squeeze(rgb_patches)\n",
    "    listofpatches = np.reshape(rgb_patches,(64,32,32,3))\n",
    "\n",
    "    #listofpatches = orig_object.reshape((1, patchsize, patchsize, 3))\n",
    "    #print(\"patches array reshaped to list of patches with shape \"+str(listofpatches.shape))\n",
    "\n",
    "    # Radon projection parameters\n",
    "    circle_inscribed = False\n",
    "    numAngles = 10\n",
    "    theta = np.linspace(0,180,numAngles,endpoint=False)\n",
    "\n",
    "    def radon_projections_compiled_cuda(patches, thetas, circle_inscribed):\n",
    "        sys.path.append(os.path.join(thispath,'build')) # for importing pysinogram.so\n",
    "        from pysinogram import BatchRadonTransform\n",
    "        return np.array(BatchRadonTransform(list(patches), list(thetas), circle_inscribed))\n",
    "\n",
    "    def radon_projections_skimage_python(patches, thetas, circle_inscribed):\n",
    "        # sqrt(abs(  2D discrete 3x3 laplacian filter  ))\n",
    "        kernel = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
    "        laplacefilter = lambda xx: np.sqrt(np.fabs(signal.convolve2d(xx, kernel, mode='same', boundary='symm')))\n",
    "        # do laplacian filter on each channel independently, then average across channels\n",
    "        rgbfilter = lambda xx: np.mean([laplacefilter(xx[:,:,chan]) for chan in range(xx.shape[2])], axis=0)\n",
    "        # transpose the sinogram output, to be consistent with CUDA implementation above\n",
    "        myradon = lambda xx: skimage.transform.radon(rgbfilter(xx), theta=theta, circle=circle_inscribed).transpose()\n",
    "        # iterate processing over all patches\n",
    "        return np.stack([myradon(patches[ii,...]) for ii in range(patches.shape[0])], axis=0)\n",
    "\n",
    "    # run tests\n",
    "    if False:\n",
    "        # compare against compiled implementation\n",
    "        # requires compiling using cuda-radon-transform repository, available on Bitbucket\n",
    "        t0 = time.time()\n",
    "        check11 =  radon_projections_compiled_cuda(listofpatches, theta, circle_inscribed)\n",
    "        t1 = time.time()\n",
    "        check22 = radon_projections_skimage_python(listofpatches, theta, circle_inscribed)\n",
    "        t2 = time.time()\n",
    "        print(\"Radon projections time, compiled CUDA:  \"+str(t1-t0)+\" seconds\")\n",
    "        print(\"Radon projections time, python skimage: \"+str(t2-t1)+\" seconds\")\n",
    "        describe(\"check11\", check11)\n",
    "        describe(\"check22\", check22)\n",
    "\n",
    "        import cv2\n",
    "        for ii in range(check11.shape[0]):\n",
    "            checkdiff = np.fabs(check11[ii,:,:] - check22[ii,:,:])\n",
    "            describe(\"checkdiff\", checkdiff)\n",
    "            zp = np.zeros((4,check11.shape[2]))\n",
    "            concat = np.concatenate((check11[ii,:,:], zp, check22[ii,:,:], zp, checkdiff), axis=0)\n",
    "            #cv2.imshow(\"npresult\", uint8norm(concat))\n",
    "            #cv2.waitKey(0)\n",
    "    else:\n",
    "        #run only one of the implementations\n",
    "        radonfunc = radon_projections_skimage_python\n",
    "        beftime = time.time()\n",
    "        npresult = radonfunc(listofpatches, theta, circle_inscribed)\n",
    "        #print(\"sinogram calculation took \"+str(time.time()-beftime)+\" seconds\")\n",
    "        #describe(\"python sinogram\", npresult)\n",
    "        assert len(npresult.shape) == 3, str(npresult.shape)\n",
    "\n",
    "        # also do FFT + normalization as final stage of feature extraction\n",
    "        # subtract 1 from normed which is the mean\n",
    "\n",
    "        absproc = lambda xx: np.expand_dims(np.absolute(xx), axis=-1)\n",
    "        beftime = time.time()\n",
    "        _, fftnormed, _, fftavg = fftscores(npresult)\n",
    "\n",
    "        npresult = absproc(fftnormed) - 1.\n",
    "        #npresult = np.concatenate([absproc(fftnormed) - 1., absproc(fftavg)], axis=1)\n",
    "        npresult=np.transpose(npresult,(3,0,1,2))\n",
    "\n",
    "        npresult=np.reshape(npresult,(64,240))\n",
    "        print (\"Feature extrating for image # \"+ str(q+1)+\", with shape-->\"+str(np.shape(npresult)))\n",
    "        #print(\"FFT calculations took \"+str(time.time()-beftime)+\" seconds\")\n",
    "        #describe(\"npresult\", npresult)\n",
    "        hdf5_file[\"feat\"][q, ...] = npresult[None]\n",
    "\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "#from tensorflow.python.ops import rnn, rnn_cell\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "# to save the data in mat file\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "from hilbert import hilbertCurve\n",
    "import skimage.io as io\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.misc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "log_device_placement = True\n",
    "# Parameters\n",
    "lr = 0.00003\n",
    "training_iters = 50000000\n",
    "batch_size = n #This value should be equal to the total files present in the directory. Ste this to len(filenames) or np.shape(feature array)[0]\n",
    "display_step = 10\n",
    "nb_nontamp_img=16960\n",
    "nb_tamp_img=68355\n",
    "nbFilter=32\n",
    "\n",
    "\n",
    "# LSTM network parameters\n",
    "n_steps = 64 # timesteps\n",
    "nBlock=int(math.sqrt(n_steps))\n",
    "n_hidden = 64# hidden layer num of features\n",
    "nStride=int(math.sqrt(n_hidden))\n",
    "# other parameters\n",
    "imSize=256\n",
    "# Network Parameters\n",
    "n_classes = 2 # manipulated vs unmanipulated\n",
    "\n",
    "\n",
    "# tf Graph input\n",
    "input_layer = tf.placeholder(\"float\", [None, imSize,imSize,3])\n",
    "y= tf.placeholder(\"float\", [2,None, imSize,imSize])\n",
    "freqFeat=tf.placeholder(\"float\", [None, 64,240])\n",
    "ratio=15.0 #tf.placeholder(\"float\",[1])\n",
    "#out_rnn=tf.placeholder(\"float\", [None, 128,128,3])\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#total_layers = 25 #Specify how deep we want our network\n",
    "units_between_stride = 2\n",
    "upsample_factor=16\n",
    "n_classes=2\n",
    "beta=.01\n",
    "outSize=16\n",
    "############################################################################\n",
    "seq = np.linspace(0,63,64).astype(int)\n",
    "order3 = hilbertCurve(3)\n",
    "order3 = np.reshape(order3,(64))\n",
    "hilbert_ind = np.lexsort((seq,order3))\n",
    "actual_ind=np.lexsort((seq,hilbert_ind))\n",
    "\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([64,64,nbFilter]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([nbFilter]))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.device('/gpu:1'):\n",
    "\n",
    "    def conv_mask_gt(z):\n",
    "        # Get ones for each class instead of a number -- we need that\n",
    "        # for cross-entropy loss later on. Sometimes the groundtruth\n",
    "        # masks have values other than 1 and 0.\n",
    "        class_labels_tensor = (z==1)\n",
    "        background_labels_tensor = (z==0)\n",
    "\n",
    "        # Convert the boolean values into floats -- so that\n",
    "        # computations in cross-entropy loss is correct\n",
    "        bit_mask_class = np.float32(class_labels_tensor)\n",
    "        bit_mask_background = np.float32(background_labels_tensor)\n",
    "        combined_mask=[]\n",
    "        combined_mask.append(bit_mask_background)\n",
    "        combined_mask.append(bit_mask_class)\n",
    "        #combined_mask = tf.concat(concat_dim=3, values=[bit_mask_background,bit_mask_class])\n",
    "\n",
    "        # Lets reshape our input so that it becomes suitable for\n",
    "        # tf.softmax_cross_entropy_with_logits with [batch_size, num_classes]\n",
    "        #flat_labels = tf.reshape(tensor=combined_mask, shape=(-1, 2))\n",
    "        return combined_mask#flat_labels\n",
    "\n",
    "    def get_kernel_size(factor):\n",
    "        #Find the kernel size given the desired factor of upsampling.\n",
    "        return 2 * factor - factor % 2\n",
    "\n",
    "    def upsample_filt(size):\n",
    "        \"\"\"\n",
    "        Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.\n",
    "        \"\"\"\n",
    "        factor = (size + 1) // 2\n",
    "        if size % 2 == 1:\n",
    "            center = factor - 1\n",
    "        else:\n",
    "            center = factor - 0.5\n",
    "        og = np.ogrid[:size, :size]\n",
    "        return (1 - abs(og[0] - center) / factor) * \\\n",
    "            (1 - abs(og[1] - center) / factor)\n",
    "\n",
    "    def bilinear_upsample_weights(factor, number_of_classes):\n",
    "        \"\"\"\n",
    "        Create weights matrix for transposed convolution with bilinear filter\n",
    "        initialization.\n",
    "        \"\"\"\n",
    "        filter_size = get_kernel_size(factor)\n",
    "\n",
    "        weights = np.zeros((filter_size,filter_size,number_of_classes,number_of_classes), dtype=np.float32)\n",
    "        upsample_kernel = upsample_filt(filter_size)\n",
    "        for i in range(number_of_classes):\n",
    "            weights[:, :, i, i] = upsample_kernel\n",
    "        return weights\n",
    "\n",
    "\n",
    "    def resUnit(input_layer,i,nbF):\n",
    "        with tf.variable_scope(\"res_unit\"+str(i)):\n",
    "        #input_layer=tf.reshape(input_layer,[-1,64,64,3])\n",
    "            part1 = slim.batch_norm(input_layer,activation_fn=None)\n",
    "            part2 = tf.nn.relu(part1)\n",
    "            part3 = slim.conv2d(part2,nbF,[3,3],activation_fn=None)\n",
    "            part4 = slim.batch_norm(part3,activation_fn=None)\n",
    "            part5 = tf.nn.relu(part4)\n",
    "            part6 = slim.conv2d(part5,nbF,[3,3],activation_fn=None)\n",
    "            output = input_layer + part6\n",
    "        return output\n",
    "\n",
    "    #tf.reset_default_graph()\n",
    "\n",
    "    def segNet(input_layer,bSize,freqFeat,weights,biases):\n",
    "        # layer1: resblock, input size(256,256)\n",
    "        layer1 = slim.conv2d(input_layer,nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(0))\n",
    "        layer1 =resUnit(layer1,1,nbFilter)\n",
    "        layer1 = tf.nn.relu(layer1)\n",
    "        layer2=slim.max_pool2d(layer1, [2, 2], scope='pool_'+str(1))\n",
    "        # layer2: resblock, input size(128,128)\n",
    "        layer2 = slim.conv2d(layer2,2*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(1))\n",
    "        layer2 =resUnit(layer2,2,2*nbFilter)\n",
    "        layer2 = tf.nn.relu(layer2)\n",
    "        layer3=slim.max_pool2d(layer2, [2, 2], scope='pool_'+str(2))\n",
    "        # layer3: resblock, input size(64,64)\n",
    "        layer3 = slim.conv2d(layer3,4*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(2))\n",
    "        layer3 =resUnit(layer3,3,4*nbFilter)\n",
    "        layer3 = tf.nn.relu(layer3)\n",
    "        layer4=slim.max_pool2d(layer3, [2, 2], scope='pool_'+str(3))\n",
    "        # layer4: resblock, input size(32,32)\n",
    "        layer4 = slim.conv2d(layer4,8*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(3))\n",
    "        layer4 =resUnit(layer4,4,8*nbFilter)\n",
    "        layer4 = tf.nn.relu(layer4)\n",
    "        layer4=slim.max_pool2d(layer4, [2, 2], scope='pool_'+str(4))\n",
    "        # end of layer4: resblock, input size(16,16)\n",
    "\n",
    "        # lstm network\n",
    "        patches=tf.transpose(freqFeat,[1,0,2])\n",
    "        patches=tf.gather(patches,hilbert_ind)\n",
    "        patches=tf.transpose(patches,[1,0,2])\n",
    "        # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "        xCell=tf.unstack(patches, n_steps, 1)\n",
    "        # 2 stacked layers\n",
    "        stacked_lstm_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(rnn.BasicLSTMCell(n_hidden),output_keep_prob=0.9) for _ in range(2)] )\n",
    "        out, state = rnn.static_rnn(stacked_lstm_cell, xCell, dtype=tf.float32)\n",
    "        # organizing the lstm output\n",
    "        out=tf.gather(out,actual_ind)\n",
    "        # convert to lstm output (64,batchSize,nbFilter)\n",
    "        lstm_out=tf.matmul(out,weights['out'])+biases['out']\n",
    "        lstm_out=tf.transpose(lstm_out,[1,0,2])\n",
    "        # convert to size(batchSize, 8,8, nbFilter)\n",
    "        lstm_out=tf.reshape(lstm_out,[bSize,8,8,nbFilter])\n",
    "        # perform batch normalization and activiation\n",
    "        lstm_out=slim.batch_norm(lstm_out,activation_fn=None)\n",
    "        lstm_out=tf.nn.relu(lstm_out)\n",
    "        # upsample lstm output to (batchSize, 16,16, nbFilter)\n",
    "        temp=tf.random_normal([bSize,outSize,outSize,nbFilter])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(2, nbFilter)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        lstm_out = tf.nn.conv2d_transpose(lstm_out, upsample_filter_tensor,output_shape=uShape1,strides=[1, 2, 2, 1])\n",
    "\n",
    "        # reduce the filter size to nbFilter for layer4\n",
    "        top = slim.conv2d(layer4,nbFilter,[1,1], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_top')\n",
    "        top = tf.nn.relu(top)\n",
    "        # concatenate both lstm features and image features\n",
    "        joint_out=tf.concat([top,lstm_out],3)\n",
    "        # perform upsampling (batchSize, 64,64, 2*nbFilter)\n",
    "        temp=tf.random_normal([bSize,outSize*4,outSize*4,2*nbFilter])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(4, 2*nbFilter)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        upsampled_layer4 = tf.nn.conv2d_transpose(joint_out, upsample_filter_tensor,output_shape=uShape1,strides=[1, 4, 4, 1])\n",
    "        # reduce filter sizes\n",
    "        upsampled_layer4 = slim.conv2d(upsampled_layer4,2,[1,1], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_'+str(4))\n",
    "        upsampled_layer4=slim.batch_norm(upsampled_layer4,activation_fn=None)\n",
    "        upsampled_layer4=tf.nn.relu(upsampled_layer4)\n",
    "        # upsampling to (batchSize, 256,256, nbClasses)\n",
    "        temp=tf.random_normal([bSize,outSize*16,outSize*16,2])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(4,2)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        upsampled_layer5 = tf.nn.conv2d_transpose(upsampled_layer4, upsample_filter_tensor,output_shape=uShape1,strides=[1, 4, 4, 1])\n",
    "        #upsampled_layer5=slim.batch_norm(upsampled_layer5,activation_fn=None)\n",
    "        #upsampled_layer5 = slim.conv2d(upsampled_layer5,2,[3,3], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_'+str(5))\n",
    "        #upsampled_layer5=tf.nn.relu(upsampled_layer5)\n",
    "\n",
    "\n",
    "        return upsampled_layer5\n",
    "\n",
    "\n",
    "    y1=tf.transpose(y,[1,2,3,0])\n",
    "    upsampled_logits=segNet(input_layer,batch_size,freqFeat,weights,biases)\n",
    "\n",
    "\n",
    "    flat_pred=tf.reshape(upsampled_logits,(-1,n_classes))\n",
    "    flat_y=tf.reshape(y1,(-1,n_classes))\n",
    "\n",
    "    #loss1=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=flat_pred,labels=flat_y))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(flat_y,flat_pred, 1.0))\n",
    "\n",
    "    trainer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    update = trainer.minimize(loss)\n",
    "    #update2 = trainer.minimize(loss2)\n",
    "\n",
    "    probabilities=tf.nn.softmax(upsampled_logits)\n",
    "    correct_pred=tf.equal(tf.argmax(probabilities,1),tf.argmax(flat_y,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "    y_actual=tf.argmax(flat_y,1)\n",
    "    y_pred=tf.argmax(flat_pred,1)\n",
    "\n",
    "    #mask_actual= tf.argmax(y1,3)\n",
    "    mask_pred=tf.argmax(upsampled_logits,3)\n",
    "\n",
    "    #mask_actual= tf.argmax(y1,3)\n",
    "    mask_p=tf.argmax(flat_pred,dimension=1)\n",
    "    mask_pred=tf.reshape(mask_p,(-1,256,256))\n",
    "    mask_act=tf.argmax(flat_y,dimension=1)\n",
    "    mask_actual=tf.reshape(mask_act,(-1,256,256))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config=tf.ConfigProto()\n",
    "config.allow_soft_placement=True\n",
    "config.log_device_placement=True\n",
    "config.gpu_options.allow_growth=True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess,'../model/final_model_nist.ckpt')\n",
    "    #print 'session starting .................!!!!'\n",
    "    subtract_mean=True\n",
    "\n",
    "    # loading NC16 data\n",
    "    mx=255.0\n",
    "    feat4=h5py.File('../test_data/test_imgs_feat_v2.hdf5','r')\n",
    "    freq4=np.array(feat4[\"feat\"])\n",
    "    feat4.close()\n",
    "\n",
    "    hdf5_file=h5py.File('../test_data/test_imgs_v2.hdf5','r')\n",
    "\n",
    "    tx=np.array(hdf5_file['test_img'])\n",
    "    tx=np.float32(tx)\n",
    "    tx= np.multiply(tx,1.0/mx) #This is done for normalization\n",
    "    ty=np.array(hdf5_file['test_labels'])\n",
    "    hdf5_file.close()\n",
    "    # ====== #\n",
    "    nTx=np.zeros((batch_size,256,256,3))\n",
    "    nTy=np.zeros((batch_size,256,256))\n",
    "    nTx1=np.zeros((batch_size,64,240))\n",
    "    n1=0\n",
    "    n2=freq4.shape[0]\n",
    "\n",
    "    for imNb in range(n1,n2):\n",
    "        nTx[imNb-n1]=tx[imNb]\n",
    "        nTy[imNb-n1]=ty[imNb]\n",
    "        nTx1[imNb-n1]=freq4[imNb]\n",
    "    #print np.shape(nTx)\n",
    "    #print np.shape(nTy)\n",
    "    #print np.shape(nTx1)\n",
    "    ty_prime=conv_mask_gt(nTy)\n",
    "    final_predictions, final_probabilities,y2=sess.run([mask_pred,probabilities,mask_actual], feed_dict={input_layer: nTx, y:ty_prime, freqFeat: nTx1})\n",
    "    #print np.shape(final_predictions)\n",
    "    #print np.shape(final_probabilities)\n",
    "\n",
    "    #sio.savemat('pred_res.mat',{'img':nTx,'labels':nTy,'pred':final_predictions,'prob':final_probabilities,'gT':y2})\n",
    "    nb = 0\n",
    "    for i in range(n1,n2):\n",
    "        #print(i)\n",
    "        cmap = plt.get_cmap('bwr')\n",
    "\t#cmap = plt.get_cmap('rainbow')\n",
    "        f,(ax,ax1,ax2,ax3)=plt.subplots(1,4,sharey=True)\n",
    "        ax.imshow(tx[i])\n",
    "        ax1.imshow(ty[i])\n",
    "        ax2.imshow(final_predictions[nb])\n",
    "        #ax3.set_title('Final Argmax')\n",
    "        probability_graph = ax3.imshow(final_probabilities.squeeze()[nb, :,:, 0])\n",
    "        nb += 1\n",
    "        #ax3.set_title('Final Probability of the Class')\n",
    "        plt.colorbar(probability_graph)\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
